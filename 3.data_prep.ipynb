{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This workbook is mainly to prepare test data in the same form of the processed train data for final predictions for Kaggle submission.\n",
    "\n",
    "A lot of the steps are just a repetition of what used in the data_expo section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:26:40.774253Z",
     "start_time": "2020-10-04T23:26:34.731416Z"
    },
    "execution": {
     "iopub.execute_input": "2020-11-07T21:44:50.465955Z",
     "iopub.status.busy": "2020-11-07T21:44:50.465955Z",
     "iopub.status.idle": "2020-11-07T21:44:53.945716Z",
     "shell.execute_reply": "2020-11-07T21:44:53.944718Z",
     "shell.execute_reply.started": "2020-11-07T21:44:50.465955Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import en_core_web_md\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import swifter\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spacy.lang.en import English\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:26:41.041540Z",
     "start_time": "2020-10-04T23:26:40.776248Z"
    },
    "execution": {
     "iopub.execute_input": "2020-11-07T21:44:53.946714Z",
     "iopub.status.busy": "2020-11-07T21:44:53.946714Z",
     "iopub.status.idle": "2020-11-07T21:44:54.117768Z",
     "shell.execute_reply": "2020-11-07T21:44:54.117768Z",
     "shell.execute_reply.started": "2020-11-07T21:44:53.946714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22513, 4)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/test.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:26:45.770923Z",
     "start_time": "2020-10-04T23:26:41.043533Z"
    },
    "execution": {
     "iopub.execute_input": "2020-11-07T21:44:54.119762Z",
     "iopub.status.busy": "2020-11-07T21:44:54.119762Z",
     "iopub.status.idle": "2020-11-07T21:44:59.198267Z",
     "shell.execute_reply": "2020-11-07T21:44:59.198267Z",
     "shell.execute_reply.started": "2020-11-07T21:44:54.119762Z"
    }
   },
   "outputs": [],
   "source": [
    "df['prod_clean'] = df['product_title'].str.lower().apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df['prod_clean'] = df['prod_clean'].apply(\n",
    "    lambda x: x.strip(string.punctuation))\n",
    "df['prod_clean'] = df['prod_clean'].str.replace('\\d+', '')\n",
    "\n",
    "df['desc_clean'] = df['product_description'].str.lower().fillna('none').apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df['desc_clean'] = df['desc_clean'].apply(\n",
    "    lambda x: x.strip(string.punctuation))\n",
    "df['desc_clean'] = df['desc_clean'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:26:47.862230Z",
     "start_time": "2020-10-04T23:26:45.771895Z"
    },
    "execution": {
     "iopub.execute_input": "2020-11-07T21:44:59.200235Z",
     "iopub.status.busy": "2020-11-07T21:44:59.200235Z",
     "iopub.status.idle": "2020-11-07T21:45:01.683344Z",
     "shell.execute_reply": "2020-11-07T21:45:01.683344Z",
     "shell.execute_reply.started": "2020-11-07T21:44:59.200235Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmat = WordNetLemmatizer()\n",
    "df['prod_lemat'] = df.apply(lambda row: lemmat.lemmatize(row['prod_clean']),\n",
    "                            axis=1)\n",
    "df['desc_lemat'] = df.apply(lambda row: lemmat.lemmatize(row['desc_clean']),\n",
    "                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:27:04.246327Z",
     "start_time": "2020-10-04T23:26:47.863219Z"
    },
    "execution": {
     "iopub.execute_input": "2020-11-07T21:45:01.685312Z",
     "iopub.status.busy": "2020-11-07T21:45:01.684314Z"
    }
   },
   "outputs": [],
   "source": [
    "df['prod_token'] = df.apply(lambda row: word_tokenize(row['prod_lemat']),\n",
    "                            axis=1)\n",
    "df['desc_token'] = df.apply(lambda row: word_tokenize(row['desc_lemat']),\n",
    "                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:27:04.437788Z",
     "start_time": "2020-10-04T23:27:04.247324Z"
    }
   },
   "outputs": [],
   "source": [
    "df['join_text'] = df['prod_token'] + df['desc_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:27:04.469704Z",
     "start_time": "2020-10-04T23:27:04.440780Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:27:04.749490Z",
     "start_time": "2020-10-04T23:27:04.471697Z"
    }
   },
   "outputs": [],
   "source": [
    "df['text'] = df['join_text'].apply(lambda x: ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:27:05.333376Z",
     "start_time": "2020-10-04T23:27:04.750488Z"
    }
   },
   "outputs": [],
   "source": [
    "df['text_fin'] = (df['text'].str.split().apply(\n",
    "    lambda x: OrderedDict.fromkeys(x).keys()).str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:27:05.365290Z",
     "start_time": "2020-10-04T23:27:05.334365Z"
    }
   },
   "outputs": [],
   "source": [
    "df_select = df[['id', 'query', 'text_fin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:27:05.381212Z",
     "start_time": "2020-10-04T23:27:05.366279Z"
    }
   },
   "outputs": [],
   "source": [
    "df_select.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:27:11.954344Z",
     "start_time": "2020-10-04T23:27:05.383206Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:29:58.428840Z",
     "start_time": "2020-10-04T23:27:11.955340Z"
    }
   },
   "outputs": [],
   "source": [
    "df_select['q_nlp'] = df_select['query'].swifter.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:35:40.493445Z",
     "start_time": "2020-10-04T23:29:58.429822Z"
    }
   },
   "outputs": [],
   "source": [
    "df_select['t_nlp'] = df_select['text_fin'].swifter.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:35:54.112588Z",
     "start_time": "2020-10-04T23:35:40.494407Z"
    }
   },
   "outputs": [],
   "source": [
    "df_select['sim'] = [\n",
    "    df_select['q_nlp'][i].similarity(df_select['t_nlp'][i])\n",
    "    for i in range(len(df_select))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:35:55.188232Z",
     "start_time": "2020-10-04T23:35:54.113585Z"
    }
   },
   "outputs": [],
   "source": [
    "df_select['fuzzy'] = [\n",
    "    fuzz.partial_ratio(df_select['query'][x], df_select['text_fin'][x])\n",
    "    for x in range(len(df_select))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:35:55.219150Z",
     "start_time": "2020-10-04T23:35:55.189230Z"
    }
   },
   "outputs": [],
   "source": [
    "df_select['query_len'] = df_select['query'].str.count(' ') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:35:55.250066Z",
     "start_time": "2020-10-04T23:35:55.220147Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading the keywords list as generated in the expolaratory stage.\n",
    "\n",
    "tup_list = pickle.load(open('data/tup_list.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:36:03.755781Z",
     "start_time": "2020-10-04T23:35:55.251064Z"
    }
   },
   "outputs": [],
   "source": [
    "for term in tup_list:\n",
    "    df_select[term] = df_select['query'].str.contains(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T23:36:09.353828Z",
     "start_time": "2020-10-04T23:36:03.756769Z"
    }
   },
   "outputs": [],
   "source": [
    "df_select.set_index('id').to_csv('./data/df_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "377.986px",
    "left": "1275.98px",
    "right": "20px",
    "top": "286.993px",
    "width": "383.75px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
