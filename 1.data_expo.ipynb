{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploratory\n",
    "\n",
    "In this section, we will apply natural languages processes step to clean up the text string, identify data pattern, and extract out relevant features that have high correlation to user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T03:51:46.635525Z",
     "start_time": "2020-10-02T03:51:43.636985Z"
    },
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:24.074024Z",
     "iopub.status.busy": "2020-11-07T21:43:24.074024Z",
     "iopub.status.idle": "2020-11-07T21:43:26.416009Z",
     "shell.execute_reply": "2020-11-07T21:43:26.415007Z",
     "shell.execute_reply.started": "2020-11-07T21:43:24.074024Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import en_core_web_md\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import swifter\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "stop = stopwords.words('english')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T03:51:46.747252Z",
     "start_time": "2020-10-02T03:51:46.684395Z"
    },
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:26.417032Z",
     "iopub.status.busy": "2020-11-07T21:43:26.417032Z",
     "iopub.status.idle": "2020-11-07T21:43:26.477669Z",
     "shell.execute_reply": "2020-11-07T21:43:26.477669Z",
     "shell.execute_reply.started": "2020-11-07T21:43:26.417032Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:26.478643Z",
     "iopub.status.busy": "2020-11-07T21:43:26.478643Z",
     "iopub.status.idle": "2020-11-07T21:43:26.493597Z",
     "shell.execute_reply": "2020-11-07T21:43:26.493597Z",
     "shell.execute_reply.started": "2020-11-07T21:43:26.478643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>median_relevance</th>\n",
       "      <th>relevance_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bridal shower decorations</td>\n",
       "      <td>Accent Pillow with Heart Design - Red/Black</td>\n",
       "      <td>Red satin accent pillow embroidered with a hea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>led christmas lights</td>\n",
       "      <td>Set of 10 Battery Operated Multi LED Train Chr...</td>\n",
       "      <td>Set of 10 Battery Operated Train Christmas Lig...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>projector</td>\n",
       "      <td>ViewSonic Pro8200 DLP Multimedia Projector</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>wine rack</td>\n",
       "      <td>Concept Housewares WR-44526 Solid-Wood Ceiling...</td>\n",
       "      <td>Like a silent and sturdy tree, the Southern En...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>light bulb</td>\n",
       "      <td>Wintergreen Lighting Christmas LED Light Bulb ...</td>\n",
       "      <td>WTGR1011\\nFeatures\\nNickel base, 60,000 averag...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      query  \\\n",
       "0   1  bridal shower decorations   \n",
       "1   2       led christmas lights   \n",
       "2   4                  projector   \n",
       "3   5                  wine rack   \n",
       "4   7                 light bulb   \n",
       "\n",
       "                                       product_title  \\\n",
       "0        Accent Pillow with Heart Design - Red/Black   \n",
       "1  Set of 10 Battery Operated Multi LED Train Chr...   \n",
       "2         ViewSonic Pro8200 DLP Multimedia Projector   \n",
       "3  Concept Housewares WR-44526 Solid-Wood Ceiling...   \n",
       "4  Wintergreen Lighting Christmas LED Light Bulb ...   \n",
       "\n",
       "                                 product_description  median_relevance  \\\n",
       "0  Red satin accent pillow embroidered with a hea...                 1   \n",
       "1  Set of 10 Battery Operated Train Christmas Lig...                 4   \n",
       "2                                                NaN                 4   \n",
       "3  Like a silent and sturdy tree, the Southern En...                 4   \n",
       "4  WTGR1011\\nFeatures\\nNickel base, 60,000 averag...                 2   \n",
       "\n",
       "   relevance_variance  \n",
       "0               0.000  \n",
       "1               0.000  \n",
       "2               0.471  \n",
       "3               0.000  \n",
       "4               0.471  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:26.494625Z",
     "iopub.status.busy": "2020-11-07T21:43:26.494625Z",
     "iopub.status.idle": "2020-11-07T21:43:26.508583Z",
     "shell.execute_reply": "2020-11-07T21:43:26.508583Z",
     "shell.execute_reply.started": "2020-11-07T21:43:26.494625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10158, 6)\n",
      "id                        0\n",
      "query                     0\n",
      "product_title             0\n",
      "product_description    2444\n",
      "median_relevance          0\n",
      "relevance_variance        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Steps\n",
    "- remove stop words, numeric values, and punctuation\n",
    "- lemmatize\n",
    "- tokenize\n",
    "- obtain simiarlity scores\n",
    "- tfdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T03:51:48.128061Z",
     "start_time": "2020-10-02T03:51:46.796097Z"
    },
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:26.510552Z",
     "iopub.status.busy": "2020-11-07T21:43:26.509554Z",
     "iopub.status.idle": "2020-11-07T21:43:27.854650Z",
     "shell.execute_reply": "2020-11-07T21:43:27.854650Z",
     "shell.execute_reply.started": "2020-11-07T21:43:26.510552Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove stop words, numbers, and punctuation\n",
    "\n",
    "df['prod_clean'] = df['product_title'].str.lower().apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df['prod_clean'] = df['prod_clean'].apply(\n",
    "    lambda x: x.strip(string.punctuation))\n",
    "df['prod_clean'] = df['prod_clean'].str.replace('\\d+', '')\n",
    "\n",
    "df['desc_clean'] = df['product_description'].str.lower().fillna('none').apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df['desc_clean'] = df['desc_clean'].apply(\n",
    "    lambda x: x.strip(string.punctuation))\n",
    "df['desc_clean'] = df['desc_clean'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:27.855623Z",
     "iopub.status.busy": "2020-11-07T21:43:27.855623Z",
     "iopub.status.idle": "2020-11-07T21:43:29.422561Z",
     "shell.execute_reply": "2020-11-07T21:43:29.421553Z",
     "shell.execute_reply.started": "2020-11-07T21:43:27.855623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lemmatize\n",
    "\n",
    "lemmat = WordNetLemmatizer()\n",
    "df['prod_lemat'] = df.apply(lambda row: lemmat.lemmatize(row['prod_clean']),\n",
    "                            axis=1)\n",
    "df['desc_lemat'] = df.apply(lambda row: lemmat.lemmatize(row['desc_clean']),\n",
    "                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:29.422561Z",
     "iopub.status.busy": "2020-11-07T21:43:29.422561Z",
     "iopub.status.idle": "2020-11-07T21:43:34.401421Z",
     "shell.execute_reply": "2020-11-07T21:43:34.400748Z",
     "shell.execute_reply.started": "2020-11-07T21:43:29.422561Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "\n",
    "df['prod_token'] = df.apply(lambda row: word_tokenize(row['prod_lemat']),\n",
    "                            axis=1)\n",
    "df['desc_token'] = df.apply(lambda row: word_tokenize(row['desc_lemat']),\n",
    "                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:34.403417Z",
     "iopub.status.busy": "2020-11-07T21:43:34.403417Z",
     "iopub.status.idle": "2020-11-07T21:43:34.431304Z",
     "shell.execute_reply": "2020-11-07T21:43:34.431304Z",
     "shell.execute_reply.started": "2020-11-07T21:43:34.403417Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine both product title and description into one feature columns\n",
    "\n",
    "df['join_text'] = df['prod_token'] + df['desc_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:34.433300Z",
     "iopub.status.busy": "2020-11-07T21:43:34.433300Z",
     "iopub.status.idle": "2020-11-07T21:43:34.512420Z",
     "shell.execute_reply": "2020-11-07T21:43:34.511419Z",
     "shell.execute_reply.started": "2020-11-07T21:43:34.433300Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert back to text string\n",
    "\n",
    "df['text'] = df['join_text'].apply(lambda x: ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:34.513415Z",
     "iopub.status.busy": "2020-11-07T21:43:34.512420Z",
     "iopub.status.idle": "2020-11-07T21:43:34.701565Z",
     "shell.execute_reply": "2020-11-07T21:43:34.700907Z",
     "shell.execute_reply.started": "2020-11-07T21:43:34.513415Z"
    }
   },
   "outputs": [],
   "source": [
    "# remvoe duplicated words\n",
    "\n",
    "df['text_fin'] = (df['text'].str.split().apply(\n",
    "    lambda x: OrderedDict.fromkeys(x).keys()).str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T03:51:48.220710Z",
     "start_time": "2020-10-02T03:51:48.206595Z"
    },
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:34.702565Z",
     "iopub.status.busy": "2020-11-07T21:43:34.702565Z",
     "iopub.status.idle": "2020-11-07T21:43:34.731986Z",
     "shell.execute_reply": "2020-11-07T21:43:34.731273Z",
     "shell.execute_reply.started": "2020-11-07T21:43:34.702565Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter out the needed colunms into a separate dataframe\n",
    "\n",
    "expo = df[['id', 'query', 'text_fin', 'median_relevance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:34.731986Z",
     "iopub.status.busy": "2020-11-07T21:43:34.731986Z",
     "iopub.status.idle": "2020-11-07T21:43:34.747718Z",
     "shell.execute_reply": "2020-11-07T21:43:34.746981Z",
     "shell.execute_reply.started": "2020-11-07T21:43:34.731986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>text_fin</th>\n",
       "      <th>median_relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bridal shower decorations</td>\n",
       "      <td>accent pillow heart design - red/black red sat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>led christmas lights</td>\n",
       "      <td>set battery operated multi led train christmas...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>projector</td>\n",
       "      <td>viewsonic pro dlp multimedia projector none</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>wine rack</td>\n",
       "      <td>concept housewares wr- solid-wood ceiling/wall...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>light bulb</td>\n",
       "      <td>wintergreen lighting christmas led light bulb ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      query  \\\n",
       "0   1  bridal shower decorations   \n",
       "1   2       led christmas lights   \n",
       "2   4                  projector   \n",
       "3   5                  wine rack   \n",
       "4   7                 light bulb   \n",
       "\n",
       "                                            text_fin  median_relevance  \n",
       "0  accent pillow heart design - red/black red sat...                 1  \n",
       "1  set battery operated multi led train christmas...                 4  \n",
       "2        viewsonic pro dlp multimedia projector none                 4  \n",
       "3  concept housewares wr- solid-wood ceiling/wall...                 4  \n",
       "4  wintergreen lighting christmas led light bulb ...                 2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Similarity score\n",
    "\n",
    "We are making an assumptions that if the products returns have high similarity in terms of context and word uses to the search queries, users would like to give a good rating.\n",
    "\n",
    "Two similarity metric which we will extract from the text string are spacy similarity score and partial ratio of fuzzywuzzy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:34.747718Z",
     "iopub.status.busy": "2020-11-07T21:43:34.747718Z",
     "iopub.status.idle": "2020-11-07T21:43:37.985774Z",
     "shell.execute_reply": "2020-11-07T21:43:37.984841Z",
     "shell.execute_reply.started": "2020-11-07T21:43:34.747718Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T21:43:37.985774Z",
     "iopub.status.busy": "2020-11-07T21:43:37.985774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b57b90f9d44bbbb5882662880f750b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=10158.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expo['q_nlp'] = expo['query'].swifter.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo['t_nlp'] = expo['text_fin'].swifter.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo['sim'] = [\n",
    "    expo['q_nlp'][i].similarity(expo['t_nlp'][i]) for i in range(len(expo))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo['fuzzy'] = [\n",
    "    fuzz.partial_ratio(expo['query'][x], expo['text_fin'][x])\n",
    "    for x in range(len(expo))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also interested to know if the length of search query would have impact on returning a good product match, so we create he feature below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo['query_len'] = expo['query'].str.count(' ') + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='median_relevance', y='sim', data=expo)\n",
    "plt.title('similarity score distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='median_relevance', y='fuzzy', data=expo)\n",
    "plt.title('fuzzy score distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : positive correlation between fuzzywuzzy/similarity scores with median_relevance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='query_len', y='median_relevance', data=expo)\n",
    "plt.title('median relevance vary by query length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo.groupby(['query_len']).agg({'median_relevance': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: Longer search queries have lower median_relevance score on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo['median_relevance'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: target variable is imbalance, with 60% of the rating being 4. We will need to modify the machine learning algorithm to account for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate list based on median_relevance. This is to preserve words that have particular strength on predicting rating 1-4\n",
    "\n",
    "med_rel_1 = expo.query('median_relevance == 1')['query'].to_list()\n",
    "med_rel_2 = expo.query('median_relevance == 2')['query'].to_list()\n",
    "med_rel_3 = expo.query('median_relevance == 3')['query'].to_list()\n",
    "med_rel_4 = expo.query('median_relevance == 4')['query'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Word features\n",
    "\n",
    "Apply Tfdif to get obtain words that are perceived to be important based on its appearance frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_1 = TfidfVectorizer(stop_words=stop, ngram_range=(1, 2))\n",
    "vect_1.fit_transform(med_rel_1)\n",
    "X_1 = vect_1.get_feature_names()\n",
    "\n",
    "vect_2 = TfidfVectorizer(stop_words=stop, ngram_range=(1, 2))\n",
    "vect_2.fit_transform(med_rel_2)\n",
    "X_2 = vect_2.get_feature_names()\n",
    "\n",
    "vect_3 = TfidfVectorizer(stop_words=stop, ngram_range=(1, 2))\n",
    "vect_3.fit_transform(med_rel_3)\n",
    "X_3 = vect_3.get_feature_names()\n",
    "\n",
    "vect_4 = TfidfVectorizer(stop_words=stop, ngram_range=(1, 2))\n",
    "vect_4.fit_transform(med_rel_4)\n",
    "X_4 = vect_4.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remvoe duplicates on words appear in multiple lists\n",
    "\n",
    "tup_list = list(set(X_1 + X_2 + X_3 + X_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the list in a pickle file to used for tranforming test set later.\n",
    "\n",
    "with open('data/tup_list.pkl', 'wb') as f:\n",
    "    pickle.dump(tup_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add key words as binary variable to the dataframe.\n",
    "\n",
    "for term in tup_list:\n",
    "    expo[term] = expo['query'].str.contains(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo.set_index('id').to_csv('./data/df_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "377.986px",
    "left": "1275.98px",
    "right": "20px",
    "top": "286.993px",
    "width": "383.75px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
